{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe782074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    accuracy_score, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score,confusion_matrix, classification_report, roc_curve, auc,f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import learning_curve, StratifiedKFold\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a926ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import import_ipynb\n",
    "from adda_boost import CustomAdaBoost\n",
    "from random_forest2 import RFModel\n",
    "from svm import CSVM\n",
    "from XG_boost import XGBboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7fbb722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ad7931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebLogModel():\n",
    "    def __init__(self):\n",
    "        with open(\"pickle/Addaboost.pkl\",\"rb\") as fd:\n",
    "            self.AdaBoost_Classifier = pickle.load(fd) \n",
    "        \n",
    "        with open(\"pickle/SVM.pkl\",\"rb\") as fd:\n",
    "            self.SVM_Classifier = pickle.load(fd) \n",
    "\n",
    "        with open(\"pickle/RandomForest.pkl\",\"rb\") as fd:\n",
    "            self.RF_Classifier = pickle.load(fd) \n",
    "        \n",
    "        with open(\"pickle/XGBoost.pkl\",\"rb\") as fd:\n",
    "            self.XGBoost_Classifier = pickle.load(fd) \n",
    "\n",
    "        print(\"models loaded\")\n",
    "\n",
    "    def predict(X):\n",
    "        y_pred_adda_boost = self.AdaBoost_Classifier.predict(X)\n",
    "        y_pred_svm = self.SVM_Classifier.predict(X)\n",
    "        y_pred_rand_forest = self.RF_Classifier.predict(X)\n",
    "        y_pred_XGB = self.XGBoost_Classifier.predict(X)\n",
    "\n",
    "        all_y_pred = [y_pred_adda_boost,y_pred_rand_forest,y_pred_XGB,y_pred_svm]\n",
    "\n",
    "        tot_votes = [0 for i in range(len_y)]\n",
    "\n",
    "        for y_pred in all_y_pred:\n",
    "            for i in range(len_y):\n",
    "                tot_votes[i] += y_pred[i]\n",
    "\n",
    "        y_pred_bagging = [1 if tot_votes[i]>=2 else 0 for i in range(len_y)]\n",
    "        return y_pred_bagging\n",
    "\n",
    "    def print_stats(y_test,y_pred):\n",
    "        self.XGBoost_Classifier.print_stats(y_test,y_pred)\n",
    "        self.XGBoost_Classifier.plot_confusion_matrix(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2e9698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "class CNN_Classifier:\n",
    "    def __init__(self):\n",
    "        self.model_path = \"my_model.keras\"\n",
    "        self.model = load_model(model_path)\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "    def predict(X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf093416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudin\\AppData\\Local\\Temp\\ipykernel_30656\\4198039419.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  session_cat[row[0]] = (row[1])\n"
     ]
    }
   ],
   "source": [
    "session_cattagory = {}\n",
    "def get_test_train_data_from_csv(hum_file = \"../parsed_data/human.csv\",bot_file = \"../parsed_data/bots.csv\"):\n",
    "\n",
    "    df_merged = get_df_merged(hum_file,bot_file)\n",
    "\n",
    "    X = df_merged.iloc[:, 1:-1].values\n",
    "    Y = df_merged.iloc[:, -1].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test,\n",
    "\n",
    "def get_df_merged(hum_file = \"../parsed_data/human.csv\",bot_file = \"../parsed_data/bots.csv\"):\n",
    "    df_bots = pd.read_csv(bot_file)\n",
    "    df_bots[\"bot\"] = 1\n",
    "    df_bots\n",
    "    for ses in df_bots.iloc[:,0].values:\n",
    "        session_cattagory[ses] = 1\n",
    "\n",
    "    df_hum = pd.read_csv(hum_file)\n",
    "    df_hum[\"bot\"] = 0\n",
    "    df_hum\n",
    "    for ses in df_hum.iloc[:,0].values:\n",
    "        session_cattagory[ses] = 0\n",
    "    df_merged = pd.concat([df_bots, df_hum], ignore_index=True, sort=False)\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "def get_seesion_cat():\n",
    "    df = get_df_merged()\n",
    "\n",
    "    session_cat = {}\n",
    "    for _,row in df[[\"session_id\",\"bot\"]].iterrows():\n",
    "        session_cat[row[0]] = (row[1])\n",
    "\n",
    "    return session_cat\n",
    "\n",
    "#load test train data\n",
    "X_train, X_test, y_train, y_test = get_test_train_data_from_csv(\"../parsed_data/human.csv\",\"../parsed_data/bots.csv\")\n",
    "df = get_df_merged(hum_file = \"../parsed_data/human.csv\",bot_file = \"../parsed_data/bots.csv\")\n",
    "session_catogory = get_seesion_cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287cca4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['071tbv7fsev5d64kb0f9jieor6', '071tbv7fsev5d64kb0f9jieor6', '071tbv7fsev5d64kb0f9jieor6', '071tbv7fsev5d64kb0f9jieor6', '071tbv7fsev5d64kb0f9jieor6']\n",
      "['cupcde8stlaqucrpahgnsiv0b2', 'cupcde8stlaqucrpahgnsiv0b2', 'cupcde8stlaqucrpahgnsiv0b2', 'cupcde8stlaqucrpahgnsiv0b2', 'cupcde8stlaqucrpahgnsiv0b2']\n",
      "['t1eo5hqdtq21m7t0gulu2henl0', 't1eo5hqdtq21m7t0gulu2henl0', 't1eo5hqdtq21m7t0gulu2henl0', 't1eo5hqdtq21m7t0gulu2henl0', 't1eo5hqdtq21m7t0gulu2henl0']\n",
      "['36rja5utab0pakj5136bi7rkop', '36rja5utab0pakj5136bi7rkop', '36rja5utab0pakj5136bi7rkop', '36rja5utab0pakj5136bi7rkop', '36rja5utab0pakj5136bi7rkop']\n",
      "['6rm870g54tcodidn4igk93cg9t', '6rm870g54tcodidn4igk93cg9t', '6rm870g54tcodidn4igk93cg9t', '6rm870g54tcodidn4igk93cg9t', '6t1t0stce6afdl4ob3hl152fnj']\n",
      "['akniekteebr1v6m9uetbh65sha', 'akniekteebr1v6m9uetbh65sha', 'akniekteebr1v6m9uetbh65sha', 'akniekteebr1v6m9uetbh65sha', 'akniekteebr1v6m9uetbh65sha']\n",
      "['dft8qvdauujqen81pdjev9po2o', 'dft8qvdauujqen81pdjev9po2o', 'dft8qvdauujqen81pdjev9po2o', 'dft8qvdauujqen81pdjev9po2o', 'dft8qvdauujqen81pdjev9po2o']\n",
      "['i6io829o6v8o8r5bo6tgoc903p', 'i6io829o6v8o8r5bo6tgoc903p', 'i6io829o6v8o8r5bo6tgoc903p', 'i6io829o6v8o8r5bo6tgoc903p', 'i6io829o6v8o8r5bo6tgoc903p']\n",
      "['oq11t11ns4t2gj9cdnl10da80s', 'oq11t11ns4t2gj9cdnl10da80s', 'oq11t11ns4t2gj9cdnl10da80s', 'oq11t11ns4t2gj9cdnl10da80s', 'oq11t11ns4t2gj9cdnl10da80s']\n",
      "['u6rj19l797n5lnvk6qlunbmp8a', 'u6rj19l797n5lnvk6qlunbmp8a', 'u6rj19l797n5lnvk6qlunbmp8a', 'u6rj19l797n5lnvk6qlunbmp8a', 'u6rj19l797n5lnvk6qlunbmp8a']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for batch in os.listdir(\"mv_data\"):\n",
    "    with open(os.path.join(\"mv_data\",batch,\"ses.txt\"),\"r\") as fd:\n",
    "        line = fd.readline()\n",
    "        session_list = [x.strip().strip(\"'\") for x in line.split(\",\")]\n",
    "        print(lst[:5])\n",
    "\n",
    "        data = np.load(dir +\"/\"+ np_file)\n",
    "            ses_id= np_file[:-4]\n",
    "            for key in data:\n",
    "                X = data[key][...,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9823ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"mv_data/batch_0/data.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5820f6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile 'mv_data/batch_0/data.npz' with keys: X, Y"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578adba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
